# Deployment Information
pods_status:
  main_pods_running: 3
  canary_pods_running: 1

# Service Information
service_endpoints:
  main_service_cluster_ip: 10.107.130.121
  canary_service_cluster_ip: 10.111.78.91

# Ingress Information
ingress_details:
  address: 10.98.185.214
  host: canary-demo.local

# Metrics
main_deployment_metrics:
  http_requests_total: 466.0
  process_cpu_seconds_total: 1.05
  process_resident_memory_bytes: 3.0363648e+07

canary_deployment_metrics:
  http_requests_total: 322.0
  process_cpu_seconds_total: 0.8700000000000001
  process_resident_memory_bytes: 3.0498816e+07

# Traffic Distribution Test
traffic_test_results:
  total_requests_sent: 1720 # Much more than needed, but wanted to make sure if it sustained the ratio.
  main_responses_received: 1398
  canary_responses_received: 322
  actual_canary_percentage: 18.72 

# Prometheus Queries
prometheus_metrics:
  main_request_rate: 0.3947137222222222 # (Used avg to measure across all three pods)
  canary_request_rate: 0.31130212500000004

# Rollback Test
rollback_test:
  previous_revision: 2
  rollback_command_used: helm rollback -n canary-demo upcommerce 1 
  time_to_rollback_seconds: 0.201s # according to time command in bash shell

# Error Budget Calculation (based on 99.9% SLO)
error_budget:
  monthly_error_budget_seconds: 2592.00
  remaining_error_budget_percentage: 100.00

# Additional Observations
observations:
  unexpected_behaviors: 
    - "Issues with the Prometheus deployment not showing the correct metrics or not detecting the ServiceMonitor"
  suggested_improvements: 
    - "An easier way to make sure that the ratio is correct. I used a bash one-liner to measure it. for i in {1..20}; do curl -s -H "Host: canary-demo.local" localhost:8082 | grep -o -e "version v[1-2]"; done | sort | uniq -c"
    - "For some reason, my Prometheus had some issues with the metrics at first and I had to redeploy it to get it to work."